---
layout: post
title: Why I Like TestCase
categories:
- best practices
- clean code
- Developer Deep Dive
- unit testing
status: publish
type: post
published: true
meta:
  _edit_last: '23'
  s2mail: 'yes'
  _aioseop_keywords: nunit, testcase, rowtest, unit testing
  _aioseop_description: NUnit's TestCase is a great attribute for working with parameterized
    tests or anytime you would like to test "given some inputs, verify some output".
  _aioseop_title: Why I Like TestCase
  dsq_thread_id: '834006333'
---
<p><a href="http://nunit.org/?p=testCase&amp;r=2.5" target="_blank">TestCase</a> is one way you can run parameterized tests with NUnit. An example of how this is useful is testing a whitelist or blacklist. You only need to write the test once, then pass in your items to test some sort of output. If the requirements change and words need to be added to or removed from your list, you simply add another entry without the need for writing another test or set of tests.</p>
<p>I've found myself using TestCase (formerly <a title="What Happened to NUnit's RowTest" href="http://stackoverflow.com/questions/4069841/what-happended-to-nunit-extensions-rowtest" target="_blank">RowTest</a>) more and more often. If you see lots of very similar tests that shared assertions, or test method names with numbers/values in them, these are signs that you might be wanting to use TestCase. Let's take a look at the following examples.<!--more--></p>
<h3><strong>One Test, Many Assertions</strong></h3>
<p>Here you can see that we have one test and many assertions. I've often seen this pattern in tests that have been around the project for a long time. It can be faster to add an assertion rather than to write a whole new test.  This might get the job done, but there are better ways.</p>
<p>{% gist 1981200 %}</p>
<p>This isn't ideal because your test can fail at the first assertion, skipping all the rest. Imagine a more complex test that fails at the first assert call and subsequent code changes make it fail at the second and so on. The feedback on the failed tests is less valuable in these situations. This is also why we don't write one test for our entire application; tests are more helpful as they become more granular.</p>
<h3><strong>Many Tests, Each with One Assertion</strong></h3>
<p>Another not so great way to test this is breaking the assertions into many tests. This also technically works, but is prone to test names representing the wrong idea if values change and the name does not. Maintenance becomes a bit tougher when they're written this way.</p>
<p>{% gist 1981202 %}</p>
<p>The reason I wouldn't recommend this is because you tend to see duplication in your values under test and your metadata (test method name). Since duplication is bad, we want to avoid this.</p>
<h3><strong>One Test, Many Values</strong></h3>
<p>A better approach is TestCase. As you'll see by the following example. We're writing the test in a way that doesn't rely on values from within the test's body, but to be supplied by attributes that are "stacked" on top.</p>
<div>{% gist 1935584 %}</div>
<p>I like this test because it's very simply testing boundary conditions. The code is largely quite discoverable and very easy to modify if our requirements were to change.</p>
<p>There's nothing magical about TestCase. It's just another tool I've found helpful when writing tests for code that I want to be able to take advantage of "given a set of inputs, verify some output".</p>
<p>What are you thoughts on this? Is TestCase new to you? Have you been using it already? Any drawbacks to using it?</p>
