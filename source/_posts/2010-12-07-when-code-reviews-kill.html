---
layout: post
title: When Code Reviews Kill
tags: []
status: pending
type: post
published: false
meta:
  _edit_last: '4'
---
<div style="margin: 2px 10px 2px 0px; float: left; width: 400px;"><img title="You may have to face a painful reality." src="http://blogs.headspring.com/content/binary/painfulreality.jpg" alt="You may have to face a painful reality." border="0" /></div>
How do you communicate what you've found in a <a href="http://www.headspringsystems.com/code-review/" target="_blank">code
review</a> when you do not have a long established relationship with the owners of
the system? The most important thing you have to do is establish a framework up front
of what the expectations of the code review are. As mentioned in our prior posting
(<a href="http://blogs.headspring.com/2010/11/24/WhatIsACodeReviewAndWhyIsItImportant.aspx" target="_blank">"What
is a code review and why is it important?"</a>) the questions you're going be trying
to answer and the areas of the system you're really interested in evaluating are going
to vary depending on both who is asking the questions and why they are interested.
<ul>
	<li>You're going to need to know the kind of information you are looking for and how it
manifests at a team level to determine if developers are working with best practices.</li>
	<li>You will need to review code in the small, immediate scope up to a more strategic
evaluation of a whole asset, possibly for acquisition, to answer the question: Does
this software asset have a viable lifetime to it in the future?</li>
	<li>Where your evaluations are going to strongly focus on architecture, you will need
to know what standards you're aiming for so that you can deliver objective information
that's valuable at the right level of clarity.<!--more--></li>
</ul>
<h2>People</h2>
Personal relationships are very important, especially in this type of offering, and
when inspecting someone's software system, where we're going to find things that are
quite good and we are going to find things which need improvement. If a code review
finds no room for improvement, then the assessors were simply not looking hard enough.
A cornerstone of success is building a relationship and that starts with <span style="color: #ff6600; font-weight: bold;">listening:</span>

<img style="margin: 4px 0px 0px 10px; float: right;" title="listening" src="http://blogs.headspring.com/content/binary/listening.jpg" alt="listening" border="0" />
<ul>
	<li>In order to perform any assessment about a software system, we have to understand
what it does. We have to understand the business model it serves and what part of
the business it enables. This requires a lot of listening.</li>
	<li>It also requires recognition that the software system has undergone tremendous change
within a successful business and that it has reacted to a changing business environment.
Without an understanding of what business and architectural decisions have been made,
we cannot form an accurate or complete understanding of the system in question.</li>
	<li>Only after listening and proving our understanding of the system in question can we
expect to have relational credit with, and trust from, the client we're serving. Our
ability to make and communicate an assessment about any software system depends on
listening.</li>
</ul>
<img title="communicating" src="http://blogs.headspring.com/content/binary/communicating.jpg" alt="communicating" border="0" />
<h2>I'd like to tell you something. You'd better have a seat.</h2>
Now the next part is communicating what we found in the code review. That needs to
stand on the shoulders of a solid relationship with the owners of the system.

To start with it's important to communicate the high level findings as it relates
to the goals of the client. For instance if it is performance or if it is scaling
or if it is load characteristics that are undesirable, we need to relate the findings
back to how it is going to allow the business to either serve more customers, serve
them faster, process more data, or be less costly to operate. If the review is a risk
and health assessment, we need to communicate the types of risks that we often see
and give a very good broad overview of what those are.

<img style="margin: 0px 0px 0px 10px; float: right;" title="an informational body of evidence and some prescriptive guidance" src="http://blogs.headspring.com/content/binary/bodyofevidence.jpg" alt="an informational body of evidence and some prescriptive guidance" border="0" />

The code review is going to produce two kinds of artifacts:
<ol>
	<li>an informational body of evidence</li>
	<li>some prescriptive guidance</li>
</ol>
Some of the stakeholders and other parties involved are going to want to really be
able to see for themselves all the documentation and possibly draw some of their own
conclusions from it, but, beyond raw reports, we want to make sure we are able to
communicate some prescriptive guidance in the service of a specific set of questions
which have guided our analysis and which the clients have posed about their software
assets. And yet, we want to make sure that we're providing not only those end recommendations
but also the body of evidence, objectively acquired, that is causing us to bring those
conclusions.

No code review is complete without offering recommendations. No one just asks for
a code review. The questions behind the questions are:
<ol>
	<li>Given what we have, where are we going?</li>
	<li>What can you do to help us get there?
<img title="questions" src="http://blogs.headspring.com/content/binary/questions.jpg" alt="questions" border="0" /></li>
</ol>
<h2>We're paid for recommendations, not criticism.</h2>
The recommendations really comprise the value that is behind a code review. Obviously,
if there is a target problem in the data center like the system slowing down or not
being able to serve all the users, then it's very concrete and obvious as to how we
may improve the performance of the system. But, if the question is "How do we insure
that our investment in this system is going to last 10 or 20 years and not expire
in 4 or 5 years?," then it's really important that the recommendations are scoped
accordingly. We've offered recommendations from performance and security improvements
all the way to how to migrate from one version of a system to another and how to ensure
that the structure of the system can last not only 20 years but can support indefinite
upgrades without the risk of becoming stale, difficult to work with, and requiring
a complete replacement.

Way too often we find systems designed with no thought to the future, and at some
point they have to be completely rewritten, with the previous investment nearly invalidated
because of some shortsighted business and architectural decisions. It may not be pleasant
for a client to hear they are trending towards such a fate, but a client ultimately
wants to know how to correct course.

<img src="http://blogs.headspring.com/aggbug.ashx?id=cb67af25-127c-43f2-b100-a06c1ad9185a" alt="" width="0" height="0" />
