<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: best practices | Headspring Labs]]></title>
  <link href="http://headspringlabs.com/blog/categories/best-practices/atom.xml" rel="self"/>
  <link href="http://headspringlabs.com/"/>
  <updated>2013-07-24T19:08:18-05:00</updated>
  <id>http://headspringlabs.com/</id>
  <author>
    <name><![CDATA[Headspring Labs]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Why I Like TestCase]]></title>
    <link href="http://headspringlabs.com/blog/why-i-like-testcase/"/>
    <updated>2012-03-14T00:00:00-05:00</updated>
    <id>http://headspringlabs.com/blog/why-i-like-testcase</id>
    <content type="html"><![CDATA[<p><a href="http://nunit.org/?p=testCase&amp;r=2.5" target="_blank">TestCase</a> is one way you can run parameterized tests with NUnit. An example of how this is useful is testing a whitelist or blacklist. You only need to write the test once, then pass in your items to test some sort of output. If the requirements change and words need to be added to or removed from your list, you simply add another entry without the need for writing another test or set of tests.</p>


<p>I've found myself using TestCase (formerly <a title="What Happened to NUnit's RowTest" href="http://stackoverflow.com/questions/4069841/what-happended-to-nunit-extensions-rowtest" target="_blank">RowTest</a>) more and more often. If you see lots of very similar tests that shared assertions, or test method names with numbers/values in them, these are signs that you might be wanting to use TestCase. Let's take a look at the following examples.</p>


<h3><strong>One Test, Many Assertions</strong></h3>


<p>Here you can see that we have one test and many assertions. I've often seen this pattern in tests that have been around the project for a long time. It can be faster to add an assertion rather than to write a whole new test.  This might get the job done, but there are better ways.</p>


<p><div><script src='https://gist.github.com/1981200.js'></script>
<noscript><pre><code></code></pre></noscript></div>
</p>


<p>This isn't ideal because your test can fail at the first assertion, skipping all the rest. Imagine a more complex test that fails at the first assert call and subsequent code changes make it fail at the second and so on. The feedback on the failed tests is less valuable in these situations. This is also why we don't write one test for our entire application; tests are more helpful as they become more granular.</p>


<h3><strong>Many Tests, Each with One Assertion</strong></h3>


<p>Another not so great way to test this is breaking the assertions into many tests. This also technically works, but is prone to test names representing the wrong idea if values change and the name does not. Maintenance becomes a bit tougher when they're written this way.</p>


<p><div><script src='https://gist.github.com/1981202.js'></script>
<noscript><pre><code></code></pre></noscript></div>
</p>


<p>The reason I wouldn't recommend this is because you tend to see duplication in your values under test and your metadata (test method name). Since duplication is bad, we want to avoid this.</p>


<h3><strong>One Test, Many Values</strong></h3>


<p>A better approach is TestCase. As you'll see by the following example. We're writing the test in a way that doesn't rely on values from within the test's body, but to be supplied by attributes that are "stacked" on top.</p>


<div><div><script src='https://gist.github.com/1935584.js'></script>
<noscript><pre><code></code></pre></noscript></div>
</div>


<p>I like this test because it's very simply testing boundary conditions. The code is largely quite discoverable and very easy to modify if our requirements were to change.</p>


<p>There's nothing magical about TestCase. It's just another tool I've found helpful when writing tests for code that I want to be able to take advantage of "given a set of inputs, verify some output".</p>


<p>What are you thoughts on this? Is TestCase new to you? Have you been using it already? Any drawbacks to using it?</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unit Testing Best Practices: Know Your Test’s Lifecycle, Part 2]]></title>
    <link href="http://headspringlabs.com/blog/unit-testing-best-practices-know-your-tests-lifecycle-part-2/"/>
    <updated>2011-09-07T00:00:00-05:00</updated>
    <id>http://headspringlabs.com/blog/unit-testing-best-practices-know-your-tests-lifecycle-part-2</id>
    <content type="html"><![CDATA[<p>In my <a title="Unit Testing Best Practices: Know your test’s lifecycle, Part 1" href="http://www.headspring.com/2011/08/unit-testing-best-practices-know-your-tests-lifecycle-part-1">first post in the Unit Testing Best Practices series</a>, I introduced you to the basic lifecycle of an NUnit test fixture. This time, we're going to see what happens when we give our tests a common test fixture base class.<br />
<span class="Apple-style-span" style="font-size: 26px"><strong>Why a base class?</strong></span><br />
There are two cases where having a base test fixture can be useful in keeping your test code simpler:</p>


<ol>
<li><strong>You have lots of the same kind of tests. </strong>Maybe you're writing integration tests for your persistence layer. Your tests are going to all be performing some similar operations, like creating a database connection. Maybe they all need to reference an Inversion of Control container like StructureMap or Autofac in order to retrieve repository instances. You don't want to write that boilerplate code for every fixture, do you?</li>
<li><strong>You have a hierarchy of classes that need testing.</strong> If you have a base class in your domain, you will probably want to set up a parallel type hierarchy of test fixtures. In this case, a base test fixture gives you one place to define tests that verify the base class invariants to which all your derived classes need to conform.</li>
</ol>


<p><span class="Apple-style-span" style="font-size: 26px"><strong>The Code</strong></span></p>


<div>Let's take a look at what happens to our simple test fixture when we give it a base class:</p>
<p><span class="Apple-style-span" style="font-family: Consolas, Monaco, monospace;font-size: 12px;line-height: 18px"><div><script src='https://gist.github.com/1262440.js'></script>
<noscript><pre><code></code></pre></noscript></div>
</span></p>
</div>


<p>Notice that the base class isn't attributed with the [TestFixture] attribute. I only want this class to act as a base for my actual fixtures. I don't intend for it to be run as a fixture in its own right.</p>


<p>Note too that I'm reinforcing the fact that this class doesn't stand alone by making the base class abstract, and following standard practices for an abstract base class by making the constructor protected instead of public. We've also made the IDisposable.Dispose method implementation virtual so we can extend its behavior in derived classes.</p>


<p><em>Test code is still code. Follow the same design practices here that you would in your application code.</em></p>


<p><span class="Apple-style-span" style="font-size: 26px"><strong>The Results</strong></span><br />
Now when we run our tests, we get the following output:</p>


<ul>
<li>Base Constructor</li>
<li>Derived Constructor</li>
<ul>
<li>Base TestFixtureSetup</li>
<li>Derived TestFixtureSetup</li>
<ul>
<li>Base SetUp</li>
<li>Derived SetUp</li>
<ul>
<li>Derived First Test passes!</li>
</ul>
<li>Derived TearDown</li>
<li>Base TearDown</li>
<li>Base SetUp</li>
<li>Derived SetUp</li>
<ul>
<li>Derived Second Test fails!</li>
</ul>
<li>Derived TearDown</li>
<li>Base TearDown</li>
<li>Base SetUp</li>
<li>Derived SetUp</li>
<ul>
<li>Base First Test passes!</li>
</ul>
<li>Derived TearDown</li>
<li>Base TearDown</li>
<li>Base SetUp</li>
<li>Derived SetUp</li>
<ul>
<li>Base Second Test fails!</li>
</ul>
<li>Derived TearDown</li>
<li>Base TearDown</li>
</ul>
<li>Derived TestFixtureTearDown</li>
<li>Base TestFixtureTearDown</li>
</ul>
<li>Derived Dispose</li>
<li>Base Dispose</li>
</ul>


<p><span class="Apple-style-span" style="font-size: 26px"><strong>Observations</strong></span><br />
Note that even with a base class, all our observations from last time are still true:</p>


<ol>
<li>The Test Fixture class is constructed once.</li>
<li>TestFixtureSetup and TestFixtureTeardDown run one time.</li>
<li>TestSetup and TestTearDown run around every test.</li>
<li>TestTearDown runs even when a test fails.</li>
<li>NUnit knows about IDisposable.</li>
</ol>


<div>But now we can also see the following new behaviors:</div>


<div>
<ol>
<li><strong>TestFixture constructors and dispose methods are called in the same order as for any other class. </strong>This is one of the reasons I prefer using constructor/disposable semantics with test fixtures instead of relying on the special FixtureSetUp/FixtureTearDown attributes - we already know the rules for constructors and disposables.</li>
<li><strong>The base class SetUp and TearDown methods run <em>around</em> those from the derived class.</strong> This is true for both Fixture- and Test- SetUp and TearDown methods. You can think of your base class wrapping your derived class, like Russian nested dolls. This pattern also extends as you create deeper inheritance hierarchies. SetUp is run from the outermost base class down to the leaf derived class, and TearDown is run in exactly the opposite order.</li>
<li><strong>All Test-level SetUp and TearDown methods are run for <em>every</em> test. </strong>This behavior is a little surprising. Notice that even on the test methods defined in the base class, <em>the derived class' SetUp and TearDown methods are still getting run</em>. If you start seeing base class tests failing because something they expected from SetUp is suddenly different, this is a likely culprit.</li>
<li><strong>Tests are run in alphabetical order</strong>. Ok, you can't infer this one from the output, you're just going to have to take my word for it (or go play with the test names yourself and see what happens.) NUnit sorts all tests on the fixture by name, from A to Z, and then runs them in that order. Base class test methods are identified as &lt;ClassName&gt;.&lt;TestMethodName&gt; for purposes of sorting. This means that your base class tests will all be grouped together when the fixture is run, but they could all run right in the middle of your derived class' tests.</li>
</ol>
</div>


<div><span class="Apple-style-span" style="font-size: 26px"><strong>Guidelines</strong></span></div>


<p>You can quickly see from the results above that our first guideline, <em>Use constructors for class-wide setup. Use IDisposable for class-wide cleanup. Avoid TestFixtureSetup and TestFixtureTearDown, </em>is even more relevant once we start creating a hierarchy of test fixtures.  Constructors and IDisposable keep our test fixtures working like any other class we'd write.</p>


<div>Let's add two more guidelines:</div>


<div>
<ol>
<li><strong>Don't rely on test run order</strong>. Test method run order varies between different hosts. NUnit and ReSharper and Gallio rarely all agree on which order to run your tests. As a developer, you're often not even running a full test suite -you're running specific fixtures, or even just a few tests within a fixture. If your tests only pass when they're run in a specific order, you're going to waste a lot of time hunting down false failures. Remember, the closer you are to release, the more likely that your tests will start failing for "no reason at all." Keep your tests independent of each other, and you'll <em>always</em> be able to run them with confidence.</li>
<li><strong>Limit test-level SetUp and TearDown semantics<em>. </em></strong>It's bad enough when a test fails. It's even worse when you have to jump around between base and derived class code to stitch together what's happening for each test. If at all possible, limit the definition of SetUp and TearDown methods to your base class. In recent years, I find that if I get my fixture initialization right in the constructor, then I rarely have to do much resetting around each individual test.</li>
</ol>
</div>


<div>You've now got a clear understanding of how an individual test fixture is created, initialized, and executed, and how that changes when the fixture has a derived class with its own lifecycle. You've also got a few more guidelines to help you keep your unit tests easy to maintain and extend.</div>


<p>Next time, we're going to see how to run our own initialization code <em>before any of our test fixtures are even created. </em></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[You're Doing Your Code Reviews Wrong!]]></title>
    <link href="http://headspringlabs.com/blog/youre-doing-your-code-reviews-wrong-2/"/>
    <updated>2011-09-02T00:00:00-05:00</updated>
    <id>http://headspringlabs.com/blog/youre-doing-your-code-reviews-wrong-2</id>
    <content type="html"><![CDATA[<p>Well, not YOU, of course. YOUR team's code reviews, I'm sure, are pleasant, productive engagements where everybody leaves feeling good about the results. They happen early and regularly in the development process, the goal of the review is well understood, and you wouldn't dream of shipping a line of code that hadn't been through your review process. Your team loves doing them, and you don't worry about who does the review because you've got a consistent standard that your whole team agrees with. You're just reading this article because there's this <em>other </em>team in the building that you think would benefit from reading it, and you're going to forward it to them when you're done reading.</p>


<p>I'm with you. Personally, I've <em>never</em> sat around a meeting table with 15 other developers, all checking their email, while one poor sacrificial lamb walked us through a line-by-line explanation of code in "Representative changeset XYZ" the day <em>after</em> we put it into production. I've <em>never</em> been told (or said!) "That's good feedback, but we don't have time to re-test those changes before the release date." And I've <em>never, ever</em> had an hours-long debate about where our braces should go.</p>


<p>Really.</p>


<p>But, for the benefit of that <em>other</em> team, I've put together some advice about  <span style="color: #000000;"><a href="http://www.headspring.com/resources/whitepapers/" target="_blank">how to conduct effective code reviews</a></span>. Some of the things I cover are:</p>


<ul>
<li>Understanding why we do code reviews in the first place</li>
<li>Using code reviews to drive quality in your products early</li>
<li>Getting a consistent code style across your team so you can focus on higher-level issues</li>
<li>And more.</li>
</ul>


<p>&nbsp;</p>


<div>Come take a look at <em><span style="color: #ff0000;"><a href="http://www.headspring.com/resources/whitepapers/" target="_blank">Conducting Effective Code Reviews</a></span></em>, and remember to share it with the guys down the hall who <em>actually</em> need it!</div>


<p>&nbsp;</p>


<p>&nbsp;</p>


<p>&nbsp;</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How pair programming benefits agile teams]]></title>
    <link href="http://headspringlabs.com/blog/pair-programming-in-agile/"/>
    <updated>2011-08-29T00:00:00-05:00</updated>
    <id>http://headspringlabs.com/blog/pair-programming-in-agile</id>
    <content type="html"><![CDATA[<div>Hands down, pair programming is one of the most valuable agile techniques, but at the same it is one of the most controversial because it can be a tough sell to a manager or non-technical stakeholder. At face value, two developers and one keyboard sounds like a perfect recipe for double the cost. The problem with that equation is it naively assumes that value is limited to the speed at which developers type, and that adding a second developer won't do any good unless he also has a keyboard to pound on. In reality though, pair programming helps agile teams solve difficult problems quicker as well as help keep your team up-to-date on the latest business and technical knowledge. I want to give you the arguments to use to quell those management fears and allow you to get all the benefits of pair programming for your agile team.</div>


<p>&nbsp;</p>


<div>Have you ever watched Wheel of Fortune with a friend, without the slightest idea what the answer could be, then your friend, thinking out-loud, says one of the words and instantly you can complete the rest of the phrase? Neither of you knew the answer, but as a team you were able to solve the problem neither of you could solve on your own. Given enough time, one of you would likely have figured it out, but by working as a team you arrived at it much quicker. When developing software, the same type of problems can pop-up, and two people can solve them quicker as a team than either could individually... and most often times, far beyond twice as quickly! When situations like these pop-up, it just makes sense from a cost perspective to pair on them so the total amount of time spent on the task is reduced.</div>


<p>&nbsp;</p>


<div>The other fundamental justification for pair programming is knowledge transfer. Knowledge transfer is the process where one person shares his wisdom with a peer. This can be done countless was, such as just sitting in a room and talking to a group of other developers, but with pair programming it is baked right it. There are two types of knowledge that can be transferred: business and technical. Transferring business knowledge, such as what must happen in a system for a user to be considered a preferred customer, help to ensure multiple developers in the organization know how the system works and mitigate risk for the company when an employee leaves. Transferring technical knowledge, such as one partner in the pair sharing a keyboard shortcut key with the other, allows developers to become more efficient in how they operate and increase their productivity over the lifetime of the project.</div>


<p>&nbsp;</p>


<div>The caveat to pair programming is you shouldn't over do it. In practice, I've found about 20% of the time I pair program, and about 80% I work solo. This varies greatly week to week, and I tend to pair program more (sometimes even 80-100%) earlier in the life-cycle of an application when there are lots of difficult portions to think though and even small design mistakes can be costly down the road. As a project becomes more mature, I usually taper down to closer to a few hours a week, and then there is more emphasis on the knowledge transfer aspect--both what business rules have been developed in parallel that I have not found out about yet as well as what can I be doing to be more efficient while developing.</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Two Reasons to Use Abstract Classes in C#]]></title>
    <link href="http://headspringlabs.com/blog/two-reasons-to-use-abstract-classes-in-c/"/>
    <updated>2011-07-29T00:00:00-05:00</updated>
    <id>http://headspringlabs.com/blog/two-reasons-to-use-abstract-classes-in-c</id>
    <content type="html"><![CDATA[<p>Do you find yourself writing the same methods over and over in different classes? Say your project needs both a "Dog" class and a "Cat" class -- do you end up writing a "sleep" method for both? What if, in two months, the client needs you to add a "possum" to the system? Do you end up going in and retyping "sleep" instructions yet again? When you're modeling a system with many similar parts, it takes way too much time and effort to keep duplicating code for each class. Imagine how hard it would be to maintain a large project with thousands of classes! Besides, it violates the DRY principle of good programming: Don't Repeat Yourself! There must be a better way.</p>


<p>Thankfully, C# has built-in features for sharing code between classes. One of these is called an "abstract class". Just create a new class with the keyword "abstract" (e.g. "public abstract class Mammal") and write in its body all the methods you would like your other classes to share in common. Since an abstract class is still a class, your "Cat" and "Dog" classes can inherit from it using a colon (e.g. "public Cat : Mammal"). This means that instead of writing a "sleep" method for each animal, you only need to write it in the "Mammal" class, and the other animals will be able to use it too.<br />
But if any class can have inheritance, why not just use a regular class? The answer is that abstract classes have two special features:</p>


<p>1. They cannot be instantiated (made into objects),<br />
2. They can have special methods called "abstract methods".</p>


<p>"Wait a minute," you may be thinking, "Why would I want a class that can't become an object?!" Sounds useless, right? However, consider the purpose of an abstract class: it contains common methods (and fields) that multiple child classes inherit from, but it does not attempt to follow these directions itself. In fact, a parent class is often missing vital information about the methods and fields it contains, because each child may use them a little bit differently. The "Mammal" abstract class only has what is common to all mammals -- since some mammals can't crawl and other mammals can't gallop, the "Mammal" class can't do either one. Imagine what would happen if you tried to instantiate a "generic" mammal: you'd get a featureless mass of hair, muscle and bone that probably wouldn't survive on its own! In the same way, it is undesirable (sometimes dangerous!) to leave a class open to instantiation when it is simply a placeholder for common features. Guard against this possibility by using an abstract class.</p>


<p>What if two classes have methods so different that the only common factor is their name? This is where an abstract method comes in handy. An abstract method looks just like a normal method, except it has the word "abstract" (e.g. "abstract exampleMethod(args);" ) and a semicolon ";" instead of body brackets "{}". What does it do? It basically tells each inheriting class to create its own method with that same name. For instance, since a dog and a bat both sleep, you could write a "sleep" method in the "Mammal" class. However, there are very few commonalities between a dog's sleep and a bat's sleep. So instead of trying to account for each individual animal's sleeping habits, you would make the "sleep" method abstract. Now the code won't even compile until each animal that inherits from "Mammal" has a method called "sleep", using the "override" keyword to replace the abstract one (e.g. "public override sleep(args) {}" ). Now even though all mammals sleep, each individual mammal can sleep in its own way. After this, you may be wondering, "Why even bother putting that method in the parent class? Each inheritor is going to have its own version anyway." You really do want to have that abstract class, not to prevent syntax errors, but to prevent human memory errors. You may know intellectually that all mammals sleep, but without a mechanism forcing you to write a "sleep" method for each mammal, it is all too easy to forget to do so. You may not even realize your mistake until you get a phone call from the client in the middle of the night. By refusing to compile until each abstract method is implemented in every inheriting class, the C# compiler is doing you a favor: it's helping you remember the obvious.</p>


<p>Abstract classes help you improve your code not only through what they can do, but also through what they can't. They can hold common features for many classes to inherit, without accidentally becoming objects themselves. They can also force you to write unique implementations of a common method, preventing human errors of forgetfulness. When you set up a class hierarchy, seriously consider whether you need a normal class to inherit from, or whether an abstract class will do. It may end up making the difference between a solid or buggy program.</p>


<p>Now, if only we had something to write the rest of our code for us...</p>

]]></content>
  </entry>
  
</feed>
